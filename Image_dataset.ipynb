{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, random\n",
    "import numpy as np\n",
    "#from parameter import letters,max_text_len\n",
    "import os.path\n",
    "\n",
    "\n",
    "MAL_VECTOR = 'ംഃഅആഇഈഉഊഋഌഎഏഐഒഓഔകഖഗഘങചഛജഝഞടഠഡഢണതഥദധനഩപഫബഭമയരറലളഴവശഷസഹാിീുൂൃെേൈൊോൌ്ൎൗൺൻർൽൾ.,'\n",
    "\n",
    "#ASCII_VECTOR = '-+=!@#$%^&*(){}[]|\\'\"\\\\/?<>;:0123456789'\n",
    "\n",
    "#ENG_VECTOR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "CHAR_VECTOR = MAL_VECTOR#+ASCII_VECTOR\n",
    "\n",
    "letters = [letter for letter in CHAR_VECTOR] # letter array\n",
    "\n",
    "num_classes = len(letters) + 1               # total length of output chars + CTC separation char\n",
    "\n",
    "img_w, img_h = 700, 32\n",
    "\n",
    "# Network parameters\n",
    "batch_size = 64\n",
    "val_batch_size = 16\n",
    "\n",
    "downsample_factor = 4\n",
    "max_text_len = 60   \n",
    "\n",
    "num = 10413\n",
    "img_dirpath =  (r'C:\\Users\\Sreelekshmi\\Desktop\\total')                \n",
    "## Input Label to Text generator\n",
    "def labels_to_text(labels):   #generated labels is converted to text taking info from CHAR_VECTOR \n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):     #label text is converted to index value taking info from CHAR_VECTOR \n",
    "    return list(map(lambda x: letters.index(x), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-79ae1bfac4e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mTextImageGenerator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_dirpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownsample_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_text_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_text_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-79ae1bfac4e9>\u001b[0m in \u001b[0;36mTextImageGenerator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextImageGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dirpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownsample_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_text_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_text_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#c1()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-00d82b82844d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, img_dirpath, img_w, img_h, batch_size, downsample_factor, num, max_text_len)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TextImageGenerator:\n",
    "    def __init__(self, img_dirpath, img_w, img_h, batch_size, downsample_factor, num,max_text_len = max_text_len):\n",
    "            \n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor      \n",
    "        self.img_dirpath = (r'C:\\Users\\Sreelekshmi\\Desktop\\total')                # image dir path\n",
    "        self.img_dir = os.listdir(self.img_dirpath)     # images list\n",
    "        self.n = num                                    # number of images\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "        \n",
    "    c1 = TextImageGenerator(img_dirpath,img_w, img_h, batch_size, downsample_factor,num, max_text_len = max_text_len)\n",
    "    #c1()\n",
    "    print(c1.img_h)\n",
    "    print(c1.img_w)\n",
    "    print(c1.batch_size)\n",
    "    print(c1.max_text_len)\n",
    "    print(c1.downsample_factor)\n",
    "    print(c1.img_dirpath)\n",
    "    print(c1.num)\n",
    "        \n",
    "        \n",
    "    \n",
    "    #__init__(self, img_dirpath, img_w, img_h, batch_size, downsample_factor, num,max_text_len = max_text_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-1457cd2ed034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" Image Loading finish...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    " def build_data(self,filename):                      # loading the entire image data into RAM, this need optimization\n",
    "        print(self.n, \" Image Loading start...\")\n",
    "        f = open(r'C:\\Users\\Sreelekshmi\\Documents\\Dataset\\deepOCR\\DB')\n",
    "        read = f.read()\n",
    "        itr = read.split('\\n')\n",
    "        j=0\n",
    "        for i, line in enumerate(itr):\n",
    "            if line != '':\n",
    "                    img_file,text = line.split(\"-\")                    \n",
    "                    if os.path.isfile(self.img_dirpath + img_file+'.png'):\n",
    "                            img = cv2.imread(self.img_dirpath + img_file+'.png', cv2.IMREAD_GRAYSCALE)\n",
    "                            ar = img.shape[0]/img.shape[1]\n",
    "                            img = cv2.resize(img, (int(self.img_h/ar), self.img_h))\n",
    "                            img = img.astype(np.float32)\n",
    "                            img = (img / 255.0) * 2.0 - 1.0            # normalizing the image to (-1-0-1) range\n",
    "                            if img.shape[1] <= self.img_w and len(text) <= self.max_text_len:\n",
    "                                #print([len(self.texts),j])\n",
    "                                self.imgs[j, :, :img.shape[1]] = img   # stores imgs  \n",
    "                                self.texts.append(text)                # stores texts\n",
    "                                j=j+1\n",
    "                                if len(self.texts) == self.n:\n",
    "                                    break                              # breaks after the specified total data need to trained.\n",
    "        print(len(self.texts))\n",
    "        print(len(self.imgs))\n",
    "        print(self.n)\n",
    "        print(len(self.texts) == len(self.imgs))\n",
    "        print(len(self.texts) == self.n)\n",
    "        print(self.n, \" Image Loading finish...\")\n",
    "        \n",
    "c2 = build_data(filename)\n",
    "c2\n",
    "    \n",
    "#build_data(self,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_sample(self):      # send one sample, increment the index to select next data \n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def next_batch(self):       # next batch generator.\n",
    "        while True:\n",
    "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])     # (batchsize(bs), 800, 32, 1)\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])             # (bs, 60)\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)  # (bs, 1) RNN input length\n",
    "            label_length = np.zeros((self.batch_size, 1))           # (bs, 1)  # RNN output true label\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()     # get each sample (h,w)\n",
    "                img = img.T                        # transpose (w,h)\n",
    "                img = np.expand_dims(img, -1)      # expand dimensions (w,h,1)\n",
    "                X_data[i] = img                    # (i,w,h,1)\n",
    "                Y_data[i,:len(text_to_labels(text))] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "\n",
    "            inputs = {\n",
    "                'the_input': X_data,               # (bs, 800, 32, 1)\n",
    "                'the_labels': Y_data,              # (bs, 60)\n",
    "                'input_length': input_length,      # (bs, 1)\n",
    "                'label_length': label_length       # (bs, 1)\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1)\n",
    "            yield (inputs, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
